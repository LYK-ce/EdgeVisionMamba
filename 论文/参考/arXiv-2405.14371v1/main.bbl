% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{achiam2023gpt}
J.~Achiam, S.~Adler, S.~Agarwal, L.~Ahmad, I.~Akkaya, F.~L. Aleman, D.~Almeida, J.~Altenschmidt, S.~Altman, S.~Anadkat \emph{et~al.}, ``Gpt-4 technical report,'' \emph{arXiv preprint arXiv:2303.08774}, 2023.

\bibitem{touvron2023Llama}
H.~Touvron, L.~Martin, K.~Stone, P.~Albert, A.~Almahairi, Y.~Babaei, N.~Bashlykov, S.~Batra, P.~Bhargava, S.~Bhosale \emph{et~al.}, ``Llama 2: Open foundation and fine-tuned chat models,'' \emph{arXiv preprint arXiv:2307.09288}, 2023.

\bibitem{anil2023palm}
R.~Anil, A.~M. Dai, O.~Firat, M.~Johnson, D.~Lepikhin, A.~Passos, S.~Shakeri, E.~Taropa, P.~Bailey, Z.~Chen \emph{et~al.}, ``Palm 2 technical report,'' \emph{arXiv preprint arXiv:2305.10403}, 2023.

\bibitem{vaswani2017attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez, {\L}.~Kaiser, and I.~Polosukhin, ``Attention is all you need,'' \emph{Advances in neural information processing systems}, vol.~30, 2017.

\bibitem{shi2016edge}
W.~Shi, J.~Cao, Q.~Zhang, Y.~Li, and L.~Xu, ``Edge computing: Vision and challenges,'' \emph{IEEE Internet of Things Journal}, vol.~3, no.~5, pp. 637--646, 2016.

\bibitem{chen2019deep}
J.~Chen and X.~Ran, ``Deep learning with edge computing: A review,'' \emph{Proceedings of the IEEE}, vol. 107, no.~8, pp. 1655--1674, 2019.

\bibitem{shen2023agile}
X.~Shen, P.~Dong, L.~Lu, Z.~Kong, Z.~Li, M.~Lin, C.~Wu, and Y.~Wang, ``Agile-quant: Activation-guided quantization for faster inference of llms on the edge,'' \emph{arXiv preprint arXiv:2312.05693}, 2023.

\bibitem{frantar2022gptq}
E.~Frantar, S.~Ashkboos, T.~Hoefler, and D.~Alistarh, ``Gptq: Accurate post-training quantization for generative pre-trained transformers,'' \emph{arXiv preprint arXiv:2210.17323}, 2022.

\bibitem{frantar2022optq}
------, ``Optq: Accurate quantization for generative pre-trained transformers,'' in \emph{The Eleventh International Conference on Learning Representations}, 2022.

\bibitem{lin2023awq}
J.~Lin, J.~Tang, H.~Tang, S.~Yang, X.~Dang, and S.~Han, ``Awq: Activation-aware weight quantization for llm compression and acceleration,'' \emph{arXiv preprint arXiv:2306.00978}, 2023.

\bibitem{xiao2023smoothquant}
G.~Xiao, J.~Lin, M.~Seznec, H.~Wu, J.~Demouth, and S.~Han, ``Smoothquant: Accurate and efficient post-training quantization for large language models,'' in \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2023, pp. 38\,087--38\,099.

\bibitem{shen2024edgeqat}
X.~Shen, Z.~Kong, C.~Yang, Z.~Han, L.~Lu, P.~Dong, C.~Lyu, C.-h. Li, X.~Guo, Z.~Shu \emph{et~al.}, ``Edgeqat: Entropy and distribution guided quantization-aware training for the acceleration of lightweight llms on the edge,'' \emph{arXiv preprint arXiv:2402.10787}, 2024.

\bibitem{wang2023privatelora}
Y.~Wang, Y.~Lin, X.~Zeng, and G.~Zhang, ``Privatelora for efficient privacy preserving llm,'' \emph{arXiv preprint arXiv:2311.14030}, 2023.

\bibitem{chen2023netgpt}
Y.~Chen, R.~Li, Z.~Zhao, C.~Peng, J.~Wu, E.~Hossain, and H.~Zhang, ``Netgpt: A native-ai network architecture beyond provisioning personalized generative services,'' 2023.

\bibitem{zhang2022eaas}
M.~Zhang, J.~Cao, Y.~Sahni, Q.~Chen, S.~Jiang, and T.~Wu, ``Eaas: A service-oriented edge computing framework towards distributed intelligence,'' in \emph{2022 IEEE International Conference on Service-Oriented System Engineering (SOSE)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2022, pp. 165--175.

\bibitem{zhang2022ents}
M.~Zhang, J.~Cao, L.~Yang, L.~Zhang, Y.~Sahni, and S.~Jiang, ``Ents: An edge-native task scheduling system for collaborative edge computing,'' in \emph{2022 IEEE/ACM 7th Symposium on Edge Computing (SEC)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2022, pp. 149--161.

\bibitem{huang2019gpipe}
Y.~Huang, Y.~Cheng, A.~Bapna, O.~Firat, D.~Chen, M.~Chen, H.~Lee, J.~Ngiam, Q.~V. Le, Y.~Wu \emph{et~al.}, ``Gpipe: Efficient training of giant neural networks using pipeline parallelism,'' \emph{Advances in neural information processing systems}, vol.~32, 2019.

\bibitem{narayanan2019pipedream}
D.~Narayanan, A.~Harlap, A.~Phanishayee, V.~Seshadri, N.~R. Devanur, G.~R. Ganger, P.~B. Gibbons, and M.~Zaharia, ``Pipedream: Generalized pipeline parallelism for dnn training,'' in \emph{Proceedings of the 27th ACM Symposium on Operating Systems Principles}, 2019, pp. 1--15.

\bibitem{devlin2018bert}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova, ``Bert: Pre-training of deep bidirectional transformers for language understanding,'' \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem{hubert2002linux}
B.~Hubert \emph{et~al.}, ``Linux advanced routing \& traffic control howto,'' \emph{Netherlabs BV}, vol.~1, pp. 99--107, 2002.

\bibitem{merity2017pointer}
S.~Merity, C.~Xiong, J.~Bradbury, and R.~Socher, ``Pointer sentinel mixture models,'' in \emph{International Conference on Learning Representations}, 2017.

\bibitem{dong2023lambo}
L.~Dong, F.~Jiang, Y.~Peng, K.~Wang, K.~Yang, C.~Pan, and R.~Schober, ``Lambo: Large language model empowered edge intelligence,'' \emph{arXiv preprint arXiv:2308.15078}, 2023.

\bibitem{jiang2023large}
F.~Jiang, L.~Dong, Y.~Peng, K.~Wang, K.~Yang, C.~Pan, D.~Niyato, and O.~A. Dobre, ``Large language model enhanced multi-agent systems for 6g communications,'' \emph{arXiv preprint arXiv:2312.07850}, 2023.

\bibitem{shen2024large}
Y.~Shen, J.~Shao, X.~Zhang, Z.~Lin, H.~Pan, D.~Li, J.~Zhang, and K.~B. Letaief, ``Large language models empowered autonomous edge ai for connected intelligence,'' \emph{IEEE Communications Magazine}, 2024.

\bibitem{rong2024leveraging}
B.~Rong and H.~Rutagemwa, ``Leveraging large language models for intelligent control of 6g integrated tn-ntn with iot service,'' \emph{IEEE Network}, 2024.

\end{thebibliography}
